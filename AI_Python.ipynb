{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Python",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPu6DePm0jyAFdlEWlj144U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodolfoFerro/ai-python/blob/master/AI_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_d6yiBH6mI6"
      },
      "source": [
        "# Taller de AI con Python\n",
        "\n",
        "Taller de AI con Python compartido para la comunidad de AI Gaming LATAM.\n",
        "\n",
        "Código documentado por **Rodolfo Ferro**, Google Developer Expert en Machine Learning.\n",
        "\n",
        "#### Redes:\n",
        "- GitHub: [RodolfoFerro](https://github.com/RodolfoFerro)\n",
        "- Twitter: [FerroRodolfo](https://twitter.com/FerroRodolfo)\n",
        "- Instagram: [rodo_ferro](https://www.instagram.com/rodo_ferro/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpQ_Qf5grrkw"
      },
      "source": [
        "## Descarga de datos\n",
        "\n",
        "Los datos se encuentran disponibles de manera pública en https://nasadata.blob.core.windows.net/nasarocks/Data.zip. El siguiente comando descargará directamente el conjunto de imágenes y descomprimirá la carpeta en Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlkL87N5raIk"
      },
      "source": [
        "!wget https://nasadata.blob.core.windows.net/nasarocks/Data.zip\n",
        "!unzip Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_0uS0ofrwJu"
      },
      "source": [
        "## Código\n",
        "\n",
        "El código a continuación va a realizar toda la magia de entrenar una red neuronal para clasificar las imágenes que hemos descargado.\n",
        "\n",
        "> **Nota:** Google Colab ya cuenta con un montón de paquetería instalada, así que con ello podemos omitir cualquier proceso de instalación y brincar directo a trabajar con el código.\n",
        "\n",
        "Comenzaremos importando las paqueterías que vamos a utilizar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqiDQcuSuw0F"
      },
      "source": [
        "# Matplotlib será nuestra biblioteca para crear gráficas.\n",
        "# Ésta contiene un módulo para ploteo que importeremos con el alias de plt.\n",
        "# Además, configuraremos parámetros sobre la calidad de las figuras.\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "matplotlib.rcParams['figure.dpi'] = 300\n",
        "\n",
        "# Ahora importamos numpy, el paquete numérico (seguramente el más \n",
        "# importante para ello) de Python.\n",
        "import numpy as np\n",
        "\n",
        "# Continuamos importando PyTorch, una biblioteca desarrololada por Facebook \n",
        "# para el desarrollo de modelos de IA con redes neuronales.\n",
        "import torch\n",
        "# Para instanciar una red neuronal y agregar un optimizador.\n",
        "from torch import nn, optim\n",
        "\n",
        "# Para diferenciación en el proceso de cómputo de gradientes.\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Agregamos funciones para sampleo de muestras (para las imágenes).\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Torchvision incluye procesamientos para trabajar con imágenes.\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "# Finalmente, importamos la Python Image Library para poder cargar las imágenes.\n",
        "from PIL import Image "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bt9xmG8lzoPw"
      },
      "source": [
        "Especificamos el folder de trabajo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwmxviTpznsK"
      },
      "source": [
        "data_dir = './Data'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2geQvg2_zs4Q"
      },
      "source": [
        "Creamos una función que cargue las imágenes y las divida en un conjunto para entrenar la red neuronal y otro para probar los resultados. \n",
        "\n",
        "> **Nota:** Normalmente partimos los datasets en dos subconjuntos, uno para entrenar el modelo con datos que sí le mostramos, y otro para medir las predicciones de la red con datos que nunca ha visto. Con esto, intentamos evitar sesgos a la hora de medir la precisión en las predicciones al tener una métrica un poco más real."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JutqiMxA0WmL"
      },
      "source": [
        "def load_split_train_test(datadir, valid_size=.2):\n",
        "    \n",
        "    # Cargamos funciones que procesen las imágenes antes de alimentar \n",
        "    # a la red neuronal, pues necesitamos definir un tamaño estándar\n",
        "    # y convertir las imagen a un tensor (generalizaciónd e una matriz).\n",
        "    train_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    test_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "    # Especificamos de dónde carga las imágenes y qué transformaciones aplica.\n",
        "    train_data = datasets.ImageFolder(datadir, transform=train_transforms)\n",
        "    test_data = datasets.ImageFolder(datadir, transform=test_transforms)\n",
        "\n",
        "    # Definimos algunos parámetros para partir el conjunto de datos y\n",
        "    # aleatorizamos el orden de las imágenes.\n",
        "    num_train = len(train_data)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # Procedemos a separar los datos en conjuntos de entrenamiento y\n",
        "    # prueba utilizando utilería de pytorch.\n",
        "    train_idx, test_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    test_sampler = SubsetRandomSampler(test_idx)\n",
        "    \n",
        "    trainloader = DataLoader(train_data, sampler=train_sampler, batch_size=16)\n",
        "    testloader = DataLoader(test_data, sampler=test_sampler, batch_size=16)\n",
        "    \n",
        "    return trainloader, testloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3ZTdCwk2ZHa"
      },
      "source": [
        "Utilizamos la función que acabamos de crear para partir las imágenes e conjuntos de entrenamiento y pruebas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lMhGEz82ZuG"
      },
      "source": [
        "trainloader, testloader = load_split_train_test(data_dir, .2)\n",
        "print(trainloader.dataset.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtO1pFHX2TJ4"
      },
      "source": [
        "Vemos que en general hay sólo 2 clases de rocas por clasificar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaAiR7hh3ZyV"
      },
      "source": [
        "Creamos otro proceso de transformaciones para las imágenes, pues nos servirá para extraer algunas imágenes de muestra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q0Xt97m4QHJ"
      },
      "source": [
        "test_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dxlrctVF4RLW"
      },
      "source": [
        "Y creamos una función más que nos ayude a extraer dicha muestra de imágenes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN6WF2fN4VrT"
      },
      "source": [
        "def get_random_images(num):\n",
        "    data = datasets.ImageFolder(data_dir, transform=test_transforms)\n",
        "    classes = data.classes\n",
        "    indices = list(range(len(data)))\n",
        "    np.random.shuffle(indices)\n",
        "    idx = indices[:num]\n",
        "    \n",
        "    sampler = SubsetRandomSampler(idx)\n",
        "    loader = torch.utils.data.DataLoader(data, sampler=sampler, batch_size=num)\n",
        "    dataiter = iter(loader)\n",
        "    images, labels = dataiter.next()\n",
        "    \n",
        "    return images, labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfmzqvn04wQW"
      },
      "source": [
        "Utilizamos esta función y visualizamos una muestra para ver cómo son las imágenes que estaremos utilizando con la red:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFbx333O4dbD"
      },
      "source": [
        "images, labels = get_random_images(5)  # Muestreo de imágenes.\n",
        "to_pil = transforms.ToPILImage()       # Transformación.\n",
        "fig = plt.figure(figsize=(20, 20))     # Creamos una figura vacía.\n",
        "classes = trainloader.dataset.classes  # Cargamos las clases.\n",
        "\n",
        "# Procedemos a añadir imágenes en una cadrícula dentro de la figura.\n",
        "for k in range(len(images)):\n",
        "    image = to_pil(images[k])\n",
        "    sub = fig.add_subplot(1, len(images), k + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CiIMFtf6Mj0"
      },
      "source": [
        "Claramente el procesamiento para la selección de buenas regiones en las imágenes puede ser mejorado..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeTk2w0S6S8I"
      },
      "source": [
        "Continuamos a configurar algunas cosas de pytorch, como el que use GPU o CPU dependiendo de tu máquina. \n",
        "\n",
        "Google Colab puede utilizar ambos, si estás ejecutando este cuaderno, previamente lo he configurado para que utilice GPUs.\n",
        "\n",
        "Además, utilizaremos un modelo precargado y pre-entrenado llamado ResNet (puedes investigar más sobre el mismo y su arquitectura, es una red neuronal convolucional, así que funciona bien con imágenes)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_ktWifW4fHi"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX1he9bn8YJ9"
      },
      "source": [
        "Con el modelo ya cargado, procedemos a agregar una capa \"full connected\", especificando algunos parámtros, como el número de neuronas, función de activación, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrGyr3dC4gq0"
      },
      "source": [
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(2048, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(512, 2),\n",
        "    nn.LogSoftmax(dim=1)\n",
        ")\n",
        "\n",
        "# Especificamos función de pérdida y optimizador.\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
        "model.to(device)\n",
        "print('Done.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epRA1zA_8zWp"
      },
      "source": [
        "Y finalmente procedemos a entrenar la red neuronal con nuestros propios datos.\n",
        "\n",
        "En general, hasta este punto ya me dio flojera documentar paso a paso lo que sigue para el entrenamiento (se me enfrían los tacos), pero en escencia lo que sucede en estos pasos es que estima una predicción inicial con los pesos precargados y calcula un error, utiliza ese error en el optimizador (gracias al gradiente) y varía los pesos hacia donde apunta el vector gradiente para intentar minimizar el error.\n",
        "\n",
        "> Si tienes dudas más específicas sobre qué hace cada línea, puedes escribirme."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhRgt7dZ4iPG"
      },
      "source": [
        "# Definimos algunos hyperparámetros.\n",
        "epochs = 5\n",
        "steps = 0\n",
        "running_loss = 0\n",
        "print_every = 5\n",
        "train_losses, test_losses = [], []\n",
        "\n",
        "# Procedemos a entrenar el modelo.\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in trainloader:\n",
        "\n",
        "        steps += 1\n",
        "        print('Training step ', steps)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logps = model.forward(inputs)\n",
        "        loss = criterion(logps, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if steps % print_every == 0:\n",
        "            test_loss = 0\n",
        "            accuracy = 0\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in testloader:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    logps = model.forward(inputs)\n",
        "                    batch_loss = criterion(logps, labels)\n",
        "                    test_loss += batch_loss.item()\n",
        "                    \n",
        "                    ps = torch.exp(logps)\n",
        "                    top_p, top_class = ps.topk(1, dim=1)\n",
        "                    equals = top_class == labels.view(*top_class.shape)\n",
        "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
        "\n",
        "            train_losses.append(running_loss/len(trainloader))\n",
        "            test_losses.append(test_loss/len(testloader))                    \n",
        "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
        "                    f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
        "                    f\"Test loss: {test_loss/len(testloader):.3f}.. \"\n",
        "                    f\"Test accuracy: {accuracy/len(testloader):.3f}\")\n",
        "            running_loss = 0\n",
        "            model.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zLfx85r-DYI"
      },
      "source": [
        "Ya que hemos entrenado el modelo, podemos medir la precisión de entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WDDa35F4mB1"
      },
      "source": [
        "print(accuracy / len(testloader))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y14Pwsvb-LWz"
      },
      "source": [
        "Si deseas guardar el modelo entrenado y descargarlo para correrlo desde una aplicación web o algo así, podemos hacerlo como sigue:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJJT2ARS-Sn6"
      },
      "source": [
        "torch.save(model, 'aerialmodel.pth')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = torch.load('aerialmodel.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw-8aaht-VmT"
      },
      "source": [
        "Ahora creamos una función para invocar al modelo y realizar la magia de inferencia para predecir las clases de imágenes de muestra.\n",
        "\n",
        "Dicha función sólo devolverá la clase predicha."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaCSHDr84n8_"
      },
      "source": [
        "def predict_image(image):\n",
        "    image_tensor = test_transforms(image).float()\n",
        "    image_tensor = image_tensor.unsqueeze_(0)\n",
        "    input = Variable(image_tensor)\n",
        "    input = input.to(device)\n",
        "    output = model(input)\n",
        "    index = output.data.cpu().numpy().argmax()\n",
        "    \n",
        "    return index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl8vexOd-jFB"
      },
      "source": [
        "Cargamos algunas imágenes random de muestra y utilizamos el modelo que entrenamos para imprimir si la clase predicha es correcta:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toRGqqVorYWj"
      },
      "source": [
        "images, labels = get_random_images(5)  # Muestreo de imágenes.\n",
        "to_pil = transforms.ToPILImage()       # Transformación.\n",
        "classes = trainloader.dataset.classes  # Cargamos las clases.\n",
        "fig = plt.figure(figsize=(20, 20))     # Creamos una figura vacía.\n",
        "\n",
        "for k in range(len(images)):\n",
        "    image = to_pil(images[k])\n",
        "    index = predict_image(image)\n",
        "    sub = fig.add_subplot(1, len(images), k + 1)\n",
        "    res = int(labels[k]) == index\n",
        "    sub.title.set_text(str(classes[index]) + \": \" + str(res))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMAX1r-XA-6n"
      },
      "source": [
        "Puedes ejecutar esta última celda varias veces para ver resultados de diferentes muestras de imágenes."
      ]
    }
  ]
}